{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea Dask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Instrucciones generales\n",
    "- Esta tarea debe realizarse de manera individual\n",
    "- Este notebook (resuelto) debe ser subido al github del proyecto en la carpeta de tareas (creen una carpeta dentro de esa carpeta y agreguen su notebook reuelto)\n",
    "- Fecha límite: Lunes 25 de noviembre de 2024 a las 11:59 p.m\n",
    "- Deben realizar las cuatro secciones\n",
    "- Puedes agregar tantas celdas de código y explicaciones como veas necesario, solo manten la estructura general"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Librerias necesarias "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import dask\n",
    "from dask import delayed, visualize\n",
    "from dask.distributed import Client, wait\n",
    "import dask.dataframe as dd\n",
    "import dask.array as da\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sección 0 Creación y Configuración del cliente de Dask\n",
    "Ejercicio 0: Configuración del cliente\n",
    "1. Crea un cliente local de Dask que inicie un clúster en tu máquina.\n",
    "2. Configura el cliente para que tenga las siguientes características (elige un par de las opciones de trabajadores e hilos):\n",
    "    - Número de trabajadores: 2 / 4\n",
    "    - Memoria máxima por trabajador: 1GB\n",
    "    - Threads por trabajador: 4 / 2\n",
    "3. Verifica que el cliente esté funcionando correctamente mostrando:\n",
    "    - Resumen de los trabajadores activos.\n",
    "    - Dashboard disponible (URL del panel de control de Dask).\n",
    "    * Tip: Checa los parámetros del cliente que creeaste.\n",
    "\n",
    "*Nota*: Puedes hacer que corra en el puerto que desees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = LocalCluster(n_workers=2, threads_per_worker=4, memory_limit=\"1GB\", dashboard_address=\":8787\" )\n",
    "\n",
    "client = Client(cluster)\n",
    "print(client)\n",
    "\n",
    "print(\"\\nResumen de trabajadores:\")\n",
    "print(client.scheduler_info()[\"workers\"])\n",
    "\n",
    "print(f\"\\nDashboard disponible en: {client.dashboard_link}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(n_workers=4, threads_per_worker=2, memory_limit='1GB')\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Sección 1 Delayed\n",
    "Ejercicio 1: Procesamiento de datos \n",
    "\n",
    "1. Genera datos simulados (por ejemplo, ventas diarias) para 10 sucursales durante 365 días.\n",
    "    - Cada sucursal debe tener datos generados aleatoriamente para \"Ingresos\" y \"Costos\".\n",
    "    - Utiliza una función para generar los datos simulados.\n",
    "2. Usa Dask Delayed para calcular:\n",
    "    - Las ganancias diarias por sucursal.\n",
    "    - La sucursal con mayor ganancia promedio.\n",
    "3. Genera un grafo de tareas que visualice estas operaciones y explica por qué elegiste paralelizar de esa forma, genera una visualización del grafo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 1: Generar datos simulados\n",
    "def generar_datos(sucursal, dias=365):\n",
    "    np.random.seed(sucursal)  # Asegurar reproducibilidad\n",
    "    ingresos = np.random.randint(1000, 10000, size=dias)\n",
    "    costos = np.random.randint(500, 8000, size=dias)\n",
    "    return pd.DataFrame({\"Sucursal\": sucursal, \"Día\": range(1, dias + 1), \"Ingresos\": ingresos, \"Costos\": costos})\n",
    "\n",
    "# Generar datos para 10 sucursales\n",
    "sucursales = [generar_datos(i) for i in range(1, 11)]\n",
    "\n",
    "# Paso 2: Definir cálculos con Dask Delayed\n",
    "@delayed\n",
    "def calcular_ganancias(df):\n",
    "    df[\"Ganancia\"] = df[\"Ingresos\"] - df[\"Costos\"]\n",
    "    return df\n",
    "\n",
    "@delayed\n",
    "def promedio_ganancia(df):\n",
    "    return df[\"Ganancia\"].mean()\n",
    "\n",
    "@delayed\n",
    "def encontrar_sucursal_mayor_promedio(promedios):\n",
    "    return max(promedios, key=lambda x: x[1])\n",
    "\n",
    "# Aplicar los cálculos con Dask Delayed\n",
    "ganancias = [calcular_ganancias(df) for df in sucursales]\n",
    "promedios = [promedio_ganancia(df) for df in ganancias]\n",
    "mayor_promedio = encontrar_sucursal_mayor_promedio(\n",
    "    delayed(list)(zip(range(1, 11), promedios))\n",
    ")\n",
    "\n",
    "# Paso 3: Generar el grafo de tareas\n",
    "visualize(mayor_promedio, filename=\"grafo_tareas\", format=\"png\")\n",
    "\n",
    "# Computar los resultados\n",
    "result = mayor_promedio.compute()\n",
    "print(f\"Sucursal con mayor ganancia promedio: {result[0]} con promedio {result[1]:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sección 2 Dask Dataframes\n",
    "Ejercicio 2: Limpieza y análisis de datos reales\n",
    "\n",
    "1. Descarga un conjunto de datos masivo (puedes usar la colección de *nycflights* que se encuentra en `data/nycflights/`).\n",
    "2. Carga los datos en un Dask DataFrame. \n",
    "    - Elige adecuadamente el número de particiones (que quepan en memoria de los `workers`)\n",
    "3. Realiza las siguientes tareas:\n",
    "    - Limpia los valores faltantes en las columnas `ArrDelay` y `DepDelay`, rellenándolos con la mediana de cada columna.\n",
    "    - Calcula el retraso promedio (`DepDelay`) por mes y aerolínea.\n",
    "    - Encuentra el aeropuerto de origen con más vuelos retrasados.\n",
    "\n",
    "*Nota*: **Evita** convertir el DataFrame a pandas e **intenta** realizar `.compute()` solo cuando sea necesario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "# Paso 1: Cargar el conjunto de datos\n",
    "ruta_datos = \"data/nycflights/*.csv\" \n",
    "df = dd.read_csv(ruta_datos, assume_missing=True)\n",
    "\n",
    "print(df.columns)\n",
    "\n",
    "# Paso 2: Limpiar valores faltantes en ArrDelay y DepDelay\n",
    "# Calcular la mediana de cada columna\n",
    "arr_delay_median = df[\"ArrDelay\"].median().compute()\n",
    "dep_delay_median = df[\"DepDelay\"].median().compute()\n",
    "\n",
    "# Rellenar valores faltantes con la mediana correspondiente\n",
    "df[\"ArrDelay\"] = df[\"ArrDelay\"].fillna(arr_delay_median)\n",
    "df[\"DepDelay\"] = df[\"DepDelay\"].fillna(dep_delay_median)\n",
    "\n",
    "# Paso 3: Calcular retraso promedio por mes y aerolínea\n",
    "# Agrupar por mes y aerolínea, luego calcular el promedio\n",
    "retraso_promedio = df.groupby([\"Month\", \"UniqueCarrier\"])[\"DepDelay\"].mean()\n",
    "\n",
    "# Paso 4: Encontrar el aeropuerto con más vuelos retrasados\n",
    "# Filtrar vuelos retrasados (retraso > 0)\n",
    "vuelos_retrasados = df[df[\"DepDelay\"] > 0]\n",
    "\n",
    "# Contar retrasos por aeropuerto de origen\n",
    "retrasos_por_aeropuerto = vuelos_retrasados.groupby(\"Origin\")[\"FlightNum\"].count().compute()\n",
    "\n",
    "# Ordenar y encontrar el aeropuerto con más retrasos\n",
    "aeropuerto_con_mas_retrasos = retrasos_por_aeropuerto.idxmax()\n",
    "max_retrasos = retrasos_por_aeropuerto.max()\n",
    "\n",
    "# Mostrar resultados\n",
    "print(f\"\\nRetraso promedio por mes y aerolínea:\\n{retraso_promedio.compute()}\")\n",
    "print(f\"\\nAeropuerto con más vuelos retrasados: {aeropuerto_con_mas_retrasos} ({max_retrasos} retrasos)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sección 3 Dask Arrays\n",
    "\n",
    "Ejercicio 3: Procesamiento numérico avanzado\n",
    "\n",
    "1. Crea un arreglo de 10,000 x 10,000 con valores aleatorios usando Dask Array, utiliza un tamaño de chunks adecuado, ¿es mejor que sean cuadrados?.\n",
    "2. Realiza las siguientes operaciones:\n",
    "    - Calcula la suma de cada fila.\n",
    "    - Encuentra la fila con el valor máximo promedio.\n",
    "    - Multiplica todo el arreglo por un factor escalar (por ejemplo, 2.5).\n",
    "3. Divide el arreglo nuevamente en 100 bloques y compara la rapidez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Crear un arreglo 10,000 x 10,000 con valores aleatorios\n",
    "# Elegimos chunks cuadrados inicialmente\n",
    "arreglo = da.random.random((10_000, 10_000), chunks=(1_000, 1_000))\n",
    "suma_filas = arreglo.sum(axis=1)\n",
    "promedios_filas = arreglo.mean(axis=1)\n",
    "fila_max_promedio = promedios_filas.argmax()\n",
    "arreglo_escalar = arreglo * 2.5\n",
    "start_time = time.time()\n",
    "suma_filas_result = suma_filas.compute()\n",
    "fila_max_promedio_result = fila_max_promedio.compute()\n",
    "arreglo_escalar_result = arreglo_escalar.compute()\n",
    "print(f\"\\nTiempo con chunks de 1,000x1,000: {time.time() - start_time:.2f} segundos\")\n",
    "\n",
    "# Redividir el arreglo en 100 bloques (chunks más pequeños)\n",
    "arreglo_redividido = arreglo.rechunk((100, 100))\n",
    "\n",
    "# Repetir las operaciones con los nuevos chunks\n",
    "start_time = time.time()\n",
    "suma_filas_result_redividido = arreglo_redividido.sum(axis=1).compute()\n",
    "fila_max_promedio_result_redividido = arreglo_redividido.mean(axis=1).argmax().compute()\n",
    "arreglo_escalar_result_redividido = (arreglo_redividido * 2.5).compute()\n",
    "print(f\"Tiempo con chunks de 100x100: {time.time() - start_time:.2f} segundos\")\n",
    "\n",
    "print(f\"\\nResultados:\")\n",
    "print(f\"- Fila con el máximo promedio (chunks originales): {fila_max_promedio_result}\")\n",
    "print(f\"- Fila con el máximo promedio (chunks redivididos): {fila_max_promedio_result_redividido}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sección 4 Futures\n",
    "Ejercicio 4: Distribución de tareas dinámicas\n",
    "\n",
    "1. Implementa una función que calcule la raíz cuadrada de una lista de 100,000 números enteros generados aleatoriamente.\n",
    "2. Divide la lista en 10 partes iguales y usa Dask Futures para calcular la raíz cuadrada de cada parte en paralelo.\n",
    "3. Recolecta los resultados y calcula:\n",
    "    - El promedio de todos los números procesados.\n",
    "    - El tiempo total de ejecución (incluyendo envío y recolección de tareas).\n",
    "4. Observa como se distribuye la carga en el cliente.\n",
    "\n",
    "*Nota*: en los ejercicios ya vimos como determinar si ya se cumplío una tarea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Paso 1: Configurar el cliente de Dask\n",
    "client = Client()  # Esto inicia un clúster local automáticamente\n",
    "\n",
    "# Paso 2: Generar una lista de 100,000 números enteros aleatorios\n",
    "tamaño_lista = 100_000\n",
    "numeros = np.random.randint(1, 10_000, size=tamaño_lista)\n",
    "\n",
    "# Paso 3: Definir la función para calcular raíces cuadradas\n",
    "def calcular_raiz_cuadrada(lista):\n",
    "    return np.sqrt(lista)\n",
    "\n",
    "# Dividir la lista en 10 partes iguales\n",
    "partes = np.array_split(numeros, 10)\n",
    "\n",
    "# Paso 4: Usar Futures para distribuir tareas\n",
    "start_time = time.time()\n",
    "futures = [client.submit(calcular_raiz_cuadrada, parte) for parte in partes]\n",
    "\n",
    "# Recolectar los resultados\n",
    "resultados = client.gather(futures)\n",
    "\n",
    "# Paso 5: Calcular el promedio de todos los números procesados\n",
    "todos_los_resultados = np.concatenate(resultados)\n",
    "promedio = todos_los_resultados.mean()\n",
    "tiempo_total = time.time() - start_time\n",
    "\n",
    "\n",
    "print(f\"\\nPromedio de las raíces cuadradas: {promedio:.2f}\")\n",
    "print(f\"Tiempo total de ejecución: {tiempo_total:.2f} segundos\")\n",
    "print(\"\\nDashboard disponible en:\")\n",
    "print(client.dashboard_link)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
