{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea Dask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Instrucciones generales\n",
    "- Esta tarea debe realizarse de manera individual\n",
    "- Este notebook (resuelto) debe ser subido al github del proyecto en la carpeta de tareas (creen una carpeta dentro de esa carpeta y agreguen su notebook reuelto)\n",
    "- Fecha límite: Lunes 25 de noviembre de 2024 a las 11:59 p.m\n",
    "- Deben realizar las cuatro secciones\n",
    "- Puedes agregar tantas celdas de código y explicaciones como veas necesario, solo manten la estructura general"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sección 0 Creación y Configuración del cliente de Dask\n",
    "Ejercicio 0: Configuración del cliente\n",
    "1. Crea un cliente local de Dask que inicie un clúster en tu máquina.\n",
    "2. Configura el cliente para que tenga las siguientes características (elige un par de las opciones de trabajadores e hilos):\n",
    "    - Número de trabajadores: 2 / 4\n",
    "    - Memoria máxima por trabajador: 1GB\n",
    "    - Threads por trabajador: 4 / 2\n",
    "3. Verifica que el cliente esté funcionando correctamente mostrando:\n",
    "    - Resumen de los trabajadores activos.\n",
    "    - Dashboard disponible (URL del panel de control de Dask).\n",
    "    * Tip: Checa los parámetros del cliente que creeaste.\n",
    "\n",
    "*Nota*: Puedes hacer que corra en el puerto que desees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu código va aquí\n",
    "from dask.distributed import Client, LocalCluster\n",
    "\n",
    "cluster = LocalCluster(\n",
    "    n_workers=2,               \n",
    "    threads_per_worker=4,      \n",
    "    memory_limit='1GB'         \n",
    ")\n",
    "\n",
    "client = Client(cluster)\n",
    "\n",
    "print(client)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Sección 1 Delayed\n",
    "Ejercicio 1: Procesamiento de datos \n",
    "\n",
    "1. Genera datos simulados (por ejemplo, ventas diarias) para 10 sucursales durante 365 días.\n",
    "    - Cada sucursal debe tener datos generados aleatoriamente para \"Ingresos\" y \"Costos\".\n",
    "    - Utiliza una función para generar los datos simulados.\n",
    "2. Usa Dask Delayed para calcular:\n",
    "    - Las ganancias diarias por sucursal.\n",
    "    - La sucursal con mayor ganancia promedio.\n",
    "3. Genera un grafo de tareas que visualice estas operaciones y explica por qué elegiste paralelizar de esa forma, genera una visualización del grafo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu código va aquí\n",
    "from dask.distributed import Client, LocalCluster\n",
    "\n",
    "cluster = LocalCluster(\n",
    "    n_workers=2,               \n",
    "    threads_per_worker=4,      \n",
    "    memory_limit='1GB'         \n",
    ")\n",
    "\n",
    "client = Client(cluster)\n",
    "\n",
    "print(client)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sección 2 Dask Dataframes\n",
    "Ejercicio 2: Limpieza y análisis de datos reales\n",
    "\n",
    "1. Descarga un conjunto de datos masivo (puedes usar la colección de *nycflights* que se encuentra en `data/nycflights/`).\n",
    "2. Carga los datos en un Dask DataFrame. \n",
    "    - Elige adecuadamente el número de particiones (que quepan en memoria de los `workers`)\n",
    "3. Realiza las siguientes tareas:\n",
    "    - Limpia los valores faltantes en las columnas `ArrDelay` y `DepDelay`, rellenándolos con la mediana de cada columna.\n",
    "    - Calcula el retraso promedio (`DepDelay`) por mes y aerolínea.\n",
    "    - Encuentra el aeropuerto de origen con más vuelos retrasados.\n",
    "\n",
    "*Nota*: **Evita** convertir el DataFrame a pandas e **intenta** realizar `.compute()` solo cuando sea necesario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "ruta_datos = \"data/nycflights/*.csv\"\n",
    "\n",
    "dtypes = {\n",
    "    \"TailNum\": \"object\",\n",
    "    \"DepDelay\": \"float64\",\n",
    "    \"ArrDelay\": \"float64\",\n",
    "    \"Origin\": \"object\",\n",
    "    \"UniqueCarrier\": \"object\",\n",
    "}\n",
    "df = dd.read_csv(ruta_datos, dtype=dtypes, assume_missing=True)\n",
    "\n",
    "df = df.repartition(npartitions=20) \n",
    "\n",
    "mediana_arrdelay = df['ArrDelay'].quantile(0.5).compute()\n",
    "mediana_depdelay = df['DepDelay'].quantile(0.5).compute()\n",
    "\n",
    "df = df.fillna({'ArrDelay': mediana_arrdelay, 'DepDelay': mediana_depdelay})\n",
    "\n",
    "retraso_promedio = (\n",
    "    df.groupby(['Month', 'UniqueCarrier'])['DepDelay']\n",
    "    .mean()\n",
    "    .compute()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "aeropuerto_con_mas_retrasos = (\n",
    "    df[df['DepDelay'] > 0]\n",
    "    .groupby('Origin')['DepDelay']\n",
    "    .count()\n",
    "    .nlargest(1)\n",
    "    .compute()\n",
    ")\n",
    "\n",
    "print(\"Retraso promedio (DepDelay) por mes y aerolínea:\")\n",
    "print(retraso_promedio)\n",
    "\n",
    "print(\"\\nAeropuerto con más vuelos retrasados:\")\n",
    "print(aeropuerto_con_mas_retrasos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sección 3 Dask Arrays\n",
    "\n",
    "Ejercicio 3: Procesamiento numérico avanzado\n",
    "\n",
    "1. Crea un arreglo de 10,000 x 10,000 con valores aleatorios usando Dask Array, utiliza un tamaño de chunks adecuado, ¿es mejor que sean cuadrados?.\n",
    "2. Realiza las siguientes operaciones:\n",
    "    - Calcula la suma de cada fila.\n",
    "    - Encuentra la fila con el valor máximo promedio.\n",
    "    - Multiplica todo el arreglo por un factor escalar (por ejemplo, 2.5).\n",
    "3. Divide el arreglo nuevamente en 100 bloques y compara la rapidez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu código va aquí\n",
    "import dask.array as da\n",
    "\n",
    "shape = (10000, 10000)\n",
    "chunk_size = (1000, 1000)\n",
    "arr = da.random.random(size=shape, chunks=chunk_size)\n",
    "\n",
    "suma_filas = arr.sum(axis=1)\n",
    "\n",
    "promedio_filas = arr.mean(axis=1)\n",
    "fila_max_promedio = da.argmax(promedio_filas).compute()\n",
    "\n",
    "arreglo_escalar = arr * 2.5\n",
    "\n",
    "n_chunks = 100\n",
    "chunk_size_repartition = (shape[0] // int(n_chunks**0.5), shape[1] // int(n_chunks**0.5))\n",
    "arr_repartido = arr.rechunk(chunk_size_repartition)\n",
    "\n",
    "import time\n",
    "\n",
    "start_original = time.time()\n",
    "suma_original = arr.sum().compute()\n",
    "time_original = time.time() - start_original\n",
    "\n",
    "start_repartido = time.time()\n",
    "suma_repartido = arr_repartido.sum().compute()\n",
    "time_repartido = time.time() - start_repartido\n",
    "\n",
    "print(f\"Suma de filas (sin computar): {suma_filas}\")\n",
    "print(f\"Fila con el valor máximo promedio: {fila_max_promedio}\")\n",
    "print(f\"Suma total del arreglo original: {suma_original}\")\n",
    "print(f\"Suma total del arreglo repartido: {suma_repartido}\")\n",
    "print(f\"Tiempo para sumar arreglo original: {time_original:.2f} segundos\")\n",
    "print(f\"Tiempo para sumar arreglo repartido: {time_repartido:.2f} segundos\")\n",
    "\n",
    "#Elegí chunks de tamaño 1,000 x 1,000 porque equilibran bien el tamaño de los datos procesados y la cantidad de tareas generadas.\n",
    "#Los chunks cuadrados suelen ser más eficientes porque las operaciones matemáticas distribuyen la carga uniformemente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sección 4 Futures\n",
    "Ejercicio 4: Distribución de tareas dinámicas\n",
    "\n",
    "1. Implementa una función que calcule la raíz cuadrada de una lista de 100,000 números enteros generados aleatoriamente.\n",
    "2. Divide la lista en 10 partes iguales y usa Dask Futures para calcular la raíz cuadrada de cada parte en paralelo.\n",
    "3. Recolecta los resultados y calcula:\n",
    "    - El promedio de todos los números procesados.\n",
    "    - El tiempo total de ejecución (incluyendo envío y recolección de tareas).\n",
    "4. Observa como se distribuye la carga en el cliente.\n",
    "\n",
    "*Nota*: en los ejercicios ya vimos como determinar si ya se cumplío una tarea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu código va aquí\n",
    "import time\n",
    "from math import sqrt\n",
    "\n",
    "client = Client()\n",
    "\n",
    "def calcular_raices(lista):\n",
    "    return [sqrt(x) for x in lista]\n",
    "\n",
    "n = 100_000\n",
    "lista = np.random.randint(1, 10_000, size=n).tolist()\n",
    "\n",
    "particiones = np.array_split(lista, 10)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "futures = [client.submit(calcular_raices, part) for part in particiones]\n",
    "\n",
    "resultados = client.gather(futures)\n",
    "\n",
    "todos_los_resultados = np.concatenate(resultados)\n",
    "promedio = np.mean(todos_los_resultados)\n",
    "\n",
    "tiempo_total = time.time() - start_time\n",
    "\n",
    "print(f\"Promedio de las raíces cuadradas: {promedio:.2f}\")\n",
    "print(f\"Tiempo total de ejecución: {tiempo_total:.2f} segundos\")\n",
    "\n",
    "client.close()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
